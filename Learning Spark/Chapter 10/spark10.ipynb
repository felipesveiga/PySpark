{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea9a8d0-1821-44d4-9503-9954cd06c721",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Machine Learning with MLlib</h1>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Iremos aprender a utilizar a spark.ml com um dataset sobre aluguéis do Airbnb em São Francisco.  \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5903a38d-a5df-4b9f-8ea8-a492d746a39c",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Data Ingestion and Exploration</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Tive que remover casas com preço 0.00 dólares e preencher valores nulos com a mediana das colunas. &#x24;'s foram deletados das colunas de preço também.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e7d719-9703-48d9-8064-ea57e7e8fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/databricks/LearningSparkV2/master/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb.csv',\n",
    "                usecols=['neighbourhood', 'room_type', 'bedrooms', 'bathrooms', 'number_of_reviews', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b0bdd6-1afc-4b34-bf03-e0cddb21543f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/18 20:09:00 WARN Utils: Your hostname, veiga-Inspiron resolves to a loopback address: 127.0.1.1; using 192.168.15.21 instead (on interface wlp7s0)\n",
      "22/06/18 20:09:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/veiga/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/18 20:09:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('C.10').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50e351f2-c791-4684-a664-21875105c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnbDF = spark.createDataFrame(df, schema='''`neighborhood` STRING, `room_type` STRING, `bathrooms` FLOAT, `bedrooms` FLOAT, `price` STRING, \n",
    "                            `number_of_reviews` INT''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d6a086-2671-48bd-8614-446fe00c29e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-----+------------+-----------+--------------------+\n",
      "|        neighborhood|      room_type|price|bathrooms_na|bedrooms_na|number_of_reviews_na|\n",
      "+--------------------+---------------+-----+------------+-----------+--------------------+\n",
      "|     Duboce Triangle|Entire home/apt|170.0|         1.0|        1.0|                 180|\n",
      "|      Bernal Heights|Entire home/apt|235.0|         1.0|        2.0|                 111|\n",
      "|         Cole Valley|   Private room| 65.0|         4.0|        1.0|                  17|\n",
      "|         Cole Valley|   Private room| 65.0|         4.0|        1.0|                   8|\n",
      "|Western Addition/...|Entire home/apt|785.0|         1.5|        2.0|                  27|\n",
      "|Western Addition/...|Entire home/apt|255.0|         1.0|        2.0|                  31|\n",
      "|    Mission District|   Private room|139.0|         1.0|        1.0|                 647|\n",
      "|        Potrero Hill|   Private room|135.0|         1.0|        1.0|                 453|\n",
      "|    Mission District|Entire home/apt|265.0|         1.0|        2.0|                 320|\n",
      "|        Lower Haight|Entire home/apt|177.0|         1.0|        3.0|                  37|\n",
      "|        Hayes Valley|Entire home/apt|194.0|         2.0|        3.0|                  14|\n",
      "|        Union Square|Entire home/apt|139.0|         1.5|        1.0|                  19|\n",
      "|      Haight-Ashbury|   Private room| 85.0|         4.0|        1.0|                   6|\n",
      "|      Haight-Ashbury|   Private room| 85.0|         3.0|        1.0|                   5|\n",
      "|          The Castro|   Private room| 79.0|         1.0|        1.0|                 390|\n",
      "|         Cole Valley|Entire home/apt|136.0|         1.0|        2.0|                  16|\n",
      "|    Mission District|Entire home/apt|215.0|         1.0|        1.0|                 103|\n",
      "|         South Beach|Entire home/apt|450.0|         2.0|        2.0|                  14|\n",
      "|          Noe Valley|Entire home/apt|107.0|         1.0|        0.0|                  61|\n",
      "|        Hayes Valley|   Private room|110.0|         1.0|        1.0|                 363|\n",
      "+--------------------+---------------+-----+------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "num_cols = ['bathrooms', 'bedrooms', 'number_of_reviews']\n",
    "airbnbDF = (airbnbDF.withColumn('price', F.substring('price', 2, 10).cast('float'))\n",
    "        .where('price>0'))\n",
    "\n",
    "# O objeto 'Imputer' retorna versões das colunas selecionadas com o devido preenchimento dos NaN'.\n",
    "imputer = Imputer(strategy='median', inputCols=num_cols, outputCols=[f'{col}_na' for col in num_cols])\n",
    "airbnbDF = imputer.fit(airbnbDF).transform(airbnbDF)\n",
    "airbnbDF = airbnbDF.drop('bathrooms', 'bedrooms', 'number_of_reviews')\n",
    "airbnbDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e5c45e-1429-47db-9f5e-00813d59b343",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Creating Training and Test Sets</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O autor ensina o funcionamento de um train-test-split e o implanta em \"AirbnbDF\".\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c01fccdd-7cd8-49ae-be6f-587dffaf40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação dos sets de treino e teste.\n",
    "trainDF, testDF = airbnbDF.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7d1ab-5294-4441-b100-4ed1b88592b8",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Preparing Features with Transformers</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O aprendizado dos algoritmos no Spark é um tanto diferente quando comparado aos do scikit-learn. Por aqui, os modelos exigem que todas as features de uma estejam contidas dentro de um vetor. Nesse sentido, é necessário criar nos datasets uma coluna adicional na qual serão adicionados os vetores.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d35f599-c296-4e5f-b882-04264d59125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+-----+------------+-----------+--------------------+--------+\n",
      "|neighborhood|      room_type|price|bathrooms_na|bedrooms_na|number_of_reviews_na|features|\n",
      "+------------+---------------+-----+------------+-----------+--------------------+--------+\n",
      "|Alamo Square|Entire home/apt| 94.0|         1.0|        0.0|                  28|   [0.0]|\n",
      "|Alamo Square|Entire home/apt|100.0|         1.0|        1.0|                  13|   [1.0]|\n",
      "|Alamo Square|Entire home/apt|136.0|         1.5|        1.0|                 211|   [1.0]|\n",
      "|Alamo Square|Entire home/apt|200.0|         1.5|        1.0|                   6|   [1.0]|\n",
      "|Alamo Square|Entire home/apt|275.0|         1.0|        2.0|                  71|   [2.0]|\n",
      "+------------+---------------+-----+------------+-----------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Essa tarefa contará com o transformador 'VectorAssembler'.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=['bedrooms_na'], outputCol='features')\n",
    "\n",
    "# Aparentemente, o 'VectorAssembler' pode funcionar sem um 'fit'.\n",
    "# Por ora, iremos usar apenas o número de quartos como variável independente.\n",
    "vecTrainDF = vecAssembler.transform(trainDF)\n",
    "\n",
    "vecTrainDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040516e-4abc-4584-834c-26ca0bb29b8b",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Using Estimators to Build Models</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Treinando uma regressão linear simples em nossos dados.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75178fa2-6329-4086-96ec-b2584656df63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/18 20:09:13 WARN Instrumentation: [e8ff97e2] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/06/18 20:09:13 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/06/18 20:09:13 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/06/18 20:09:13 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol='features', labelCol='price')\n",
    "\n",
    "# LinearRegression.fit() nos retorna o transformador LinearRegressionModel, responsável por fazer previsões.\n",
    "lrModel = lr.fit(vecTrainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87b8aced-864b-4ac0-800b-a7e65802f157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DenseVector([88.4463]), 74.90401139425546)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo os coeficiente e o intercept do modelo.\n",
    "lrModel.coefficients, lrModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c011f6dc-15aa-4730-84dd-bb0dfc4b67b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epsilon: The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber (default: 1.35)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interessante! Use 'explainParam' para obter uma breve descrição sobre a utilidade de um dado argumento.\n",
    "lrModel.explainParam('epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ed1bc-d8a4-455a-bf99-ed76fb92ab92",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Creating a Pipeline</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Assim como no scikit-learn, podemos criar Pipelines de transformação dos dados a fim de facilitar futuras manipulações.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eade9ebe-3170-4e04-bba8-357740211658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/18 20:09:15 WARN Instrumentation: [5aa69a5f] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+-----+------------+-----------+--------------------+--------+------------------+\n",
      "|  neighborhood|      room_type|price|bathrooms_na|bedrooms_na|number_of_reviews_na|features|        prediction|\n",
      "+--------------+---------------+-----+------------+-----------+--------------------+--------+------------------+\n",
      "|  Alamo Square|Entire home/apt|100.0|         1.0|        1.0|                  65|   [1.0]|163.35027466456214|\n",
      "|  Alamo Square|Entire home/apt|300.0|         2.0|        3.0|                  10|   [3.0]| 340.2428012051755|\n",
      "|  Alamo Square|Entire home/apt|785.0|         1.5|        2.0|                   3|   [2.0]| 251.7965379348688|\n",
      "|Balboa Terrace|Entire home/apt|125.0|         1.0|        2.0|                 321|   [2.0]| 251.7965379348688|\n",
      "|Balboa Terrace|   Private room| 49.0|         3.0|        1.0|                  75|   [1.0]|163.35027466456214|\n",
      "+--------------+---------------+-----+------------+-----------+--------------------+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vamos criar uma Pipeline que transforme o dataset de teste. Afinal, ele tem que estar em condições semelhantes ao de treino\n",
    "# para que as previsões sejam possíveis.\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Assim como a Regressão Logística, 'fit' cria um PipelineModel.\n",
    "# Adaptando a pipeline ao dataset de treino\n",
    "pipelineModel = Pipeline(stages=[vecAssembler, lr]).fit(trainDF)\n",
    "\n",
    "# As previsões do modelo são apresentadas como uma coluna no dataset. E observe: elas são calculadas com um 'transform', e não 'predict'.                                                                                                                                 \n",
    "pipelineModel.transform(testDF).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195c8ee-efc7-4b40-a672-407aa8b2a744",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> One-hot encoding</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd2507-0d32-42fe-9053-e59ac82fb1f1",
   "metadata": {},
   "source": [
    "<p style='color:red'> Fazer a explicação do One-hot encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
